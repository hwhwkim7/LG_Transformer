import os
import glob
import argparse
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split

# íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ CSV íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
def get_csv_files(input_dir, include_keywords):
    all_csvs = glob.glob(os.path.join(input_dir, "*.csv"))
    selected = []
    for path in all_csvs:
        fname = os.path.basename(path)
        if any(kw in fname for kw in include_keywords):
            selected.append(path)
    return selected

# ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ìœˆë„ìš° ë‹¨ìœ„ë¡œ ìë¥´ê¸°
def make_windows(seq, window_size, stride):
    T, C = seq.shape
    starts = np.arange(0, T - window_size + 1, stride)
    windows = [seq[s:s+window_size] for s in starts]
    return np.array(windows)  # (ìœˆë„ìš°ê°œìˆ˜, window_size, C)

# ìœˆë„ìš° ìƒ˜í”Œë§ (ìµœëŒ€ max_kê°œê¹Œì§€)
def sample_windows(windows, max_k, seed=42):
    np.random.seed(seed)
    M = len(windows)
    if M <= max_k:
        return windows
    idx = np.random.choice(M, size=max_k, replace=False)
    return windows[idx]

# CSV ì½ê¸° (ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„)
def read_csv_encod(path):
    READ_ENCODING_CANDIDATES = ["utf-8-sig", "utf-8", "cp949", "euc-kr", "latin1"]
    for enc in READ_ENCODING_CANDIDATES:
        try:
            df = pd.read_csv(path, encoding=enc)
            return df
        except UnicodeDecodeError:
            continue
    else:
        return None

# CSVì—ì„œ ì‹œí€€ìŠ¤ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì‚¬ìš©)
def load_sequence_from_csv(path, drop_cols=None):
    df = read_csv_encod(path)
    if df is None: return None
    if drop_cols:
        df = df.drop(columns=drop_cols, errors="ignore")

    num_df = df.select_dtypes(include="number")

    if num_df.empty:
        raise ValueError(f"No numeric columns found in {path}")

    return num_df.values.astype(np.float32)  # (T, C)

# Manifest íŒŒì¼ ìƒì„± (ë©”íƒ€ë°ì´í„°: path, row/col ê°œìˆ˜, label)
def make_manifest(files, output_path):
    rows = []
    normal = 0
    leak = 0
    for path in files:
        try:
            df = read_csv_encod(path)
            num_df = df.select_dtypes(include="number")
            n_row, n_col = num_df.shape
            if 'ì •ìƒ' in path: label = 0
            elif 'ëˆ„ìˆ˜' in path: label = 1
        except Exception as e:
            print(f"âš ï¸ {path} ì½ê¸° ì‹¤íŒ¨: {e}")
            n_row, n_col = None, None
            label = None
        if label == 1:
            leak += 1
        elif label == 0:
            normal += 1

        rows.append({
            "path": path,
            "n_col": n_col,
            "n_row": n_row,
            "label": label
        })

    manifest = pd.DataFrame(rows)
    summary_row = pd.DataFrame([{
        "path": "TOTAL",
        "n_col": "",
        "n_row": "",
        "label": f"ì •ìƒ:{normal}, ëˆ„ìˆ˜:{leak}"
    }])
    manifest = pd.concat([manifest, summary_row], ignore_index=True)
    manifest.to_csv(output_path, index=False, encoding="utf-8-sig")
    print(f"âœ… Manifest ì €ì¥ ì™„ë£Œ: {output_path}")
    return manifest

# Train/Val/Test ë¶„í•  í›„ manifest ê°±ì‹ 
def split_manifest(manifest_path, train, test, valid, seed=42):
    df = pd.read_csv(manifest_path)
    total_row = df[df["path"] == "TOTAL"].copy()
    df_files = df[df["path"] != "TOTAL"].copy()

    updated = []
    for label in [0, 1]:
        group = df_files[df_files["label"] == str(label)]
        if group.empty:
            continue

        train_df, temp_df = train_test_split(
            group, test_size=(1 - train), random_state=seed, shuffle=True
        )
        val_ratio = valid / (valid + test)
        val_df, test_df = train_test_split(
            temp_df, test_size=(1 - val_ratio), random_state=seed, shuffle=True)

        train_df.loc[:, "split"] = "train"
        val_df.loc[:, "split"] = "val"
        test_df.loc[:, "split"] = "test"

        updated.extend([train_df, val_df, test_df])

    out_df = pd.concat(updated, ignore_index=True)
    split_counts = out_df.groupby(["split", "label"]).size().unstack(fill_value=0)
    train_norm, train_leak = split_counts.loc["train", '0'], split_counts.loc["train", '1']
    val_norm, val_leak = split_counts.loc["val", '0'], split_counts.loc["val", '1']
    test_norm, test_leak = split_counts.loc["test", '0'], split_counts.loc["test", '1']

    summary_row = pd.DataFrame([{
        "path": "TOTAL",
        "n_col": "",
        "n_row": "",
        "label": (
            f"ì •ìƒ:{(out_df['label'] == '0').sum()}, "
            f"ëˆ„ìˆ˜:{(out_df['label'] == '1').sum()}, "
            f"train(ì •ìƒ:{train_norm}, ëˆ„ìˆ˜:{train_leak}), "
            f"val(ì •ìƒ:{val_norm}, ëˆ„ìˆ˜:{val_leak}), "
            f"test(ì •ìƒ:{test_norm}, ëˆ„ìˆ˜:{test_leak})"
        )
    }])

    final_df = pd.concat([out_df, summary_row], ignore_index=True)
    final_df.to_csv(manifest_path, index=False, encoding="utf-8-sig")
    print("âœ… manifest ì—…ë°ì´íŠ¸ ì™„ë£Œ (split ìš”ì•½ í¬í•¨)")
    return final_df

# ì‹œí€€ìŠ¤ ë‹¨ìœ„ z-score ì •ê·œí™”
def zscore_per_sequence(arr, eps=1e-8):
    mean = arr.mean(axis=0, keepdims=True)
    std  = arr.std(axis=0, keepdims=True)
    std  = np.where(std < eps, 1.0, std)   # 0 ë‚˜ëˆ—ì…ˆ ë°©ì§€
    zarr = (arr - mean) / std
    return zarr.astype(np.float32, copy=False), mean.squeeze(0), std.squeeze(0)

# manifest ê¸°ë°˜ìœ¼ë¡œ ìœˆë„ìš° ë°ì´í„°ì…‹ ë§Œë“¤ê¸° + ì €ì¥
def build_windows_from_manifest(manifest_path, window_size, stride, max_k, out_dir):
    df = pd.read_csv(manifest_path)
    df_files = df[df["path"] != "TOTAL"].copy()
    os.makedirs(out_dir, exist_ok=True)

    stats_rows = []  # CSVë¡œ ì €ì¥í•  í–‰ë“¤
    for split in ["train", "val", "test"]:
        split_files = df_files[df_files["split"] == split]
        all_wins, all_labels, all_ids = [], [], []
        s_id = 0
        for _, row in split_files.iterrows():
            seq = load_sequence_from_csv(row["path"], drop_cols=None)
            if seq is None or len(seq) < window_size:
                continue

            # ---- ë””ë°”ì´ìŠ¤ë³„ z-score ----
            seq_z, mean_c, std_c = zscore_per_sequence(seq)
            # í†µê³„ ì €ì¥ (í‰ê· /í‘œì¤€í¸ì°¨ ë²¡í„°ë¥¼ ë¬¸ìì—´ë¡œ ì €ì¥)
            stats_rows.append({
                "path": row["path"],
                "label": row["label"],
                "split": split,
                "mean": ",".join(map(str, mean_c)),
                "std": ",".join(map(str, std_c))
            })
            # -----------------------------------
            wins = make_windows(seq_z, window_size, stride)
            wins = sample_windows(wins, max_k)

            if len(wins) == 0:
                continue

            all_wins.append(wins)
            all_labels.extend([row["label"]] * len(wins))
            all_ids.extend([s_id] * len(wins))
            s_id += 1

        if not all_wins:
            print(f"âš ï¸ {split} splitì— ìœˆë„ìš° ì—†ìŒ")
            continue

        X = np.concatenate(all_wins, axis=0).astype(np.float32)  # (N, L, C)
        y = np.array(all_labels, dtype=np.int64)  # (N,)
        seq_ids = np.array(all_ids, dtype=np.int64)  # (N,)

        np.save(os.path.join(out_dir, f"{split}_windows.npy"), X)
        np.save(os.path.join(out_dir, f"{split}_labels.npy"), y)
        np.save(os.path.join(out_dir, f"{split}_seq_ids.npy"), seq_ids)  # âœ ì €ì¥
        # print(f"âœ… {split}: X={X.shape}, y={y.shape}, seq_ids={seq_ids.shape}")

        # ---- í†µê³„ CSV ì €ì¥ ----
    stats_df = pd.DataFrame(stats_rows)
    stats_csv_path = os.path.join(out_dir, "per_sequence_zscore_stats.csv")
    stats_df.to_csv(stats_csv_path, index=False, encoding="utf-8-sig")
    print(f"ğŸ“Š Z-score í†µê³„ ì €ì¥ ì™„ë£Œ: {stats_csv_path}")

def processor(args):
    keywords = ["normal", "leak", 'ì •ìƒ', 'ëˆ„ìˆ˜']  # íŒŒì¼ëª…ì— í¬í•¨ë˜ì–´ì•¼ í•˜ëŠ” ë¬¸ìì—´ë“¤
    files = get_csv_files(args.input_folder_path, keywords)
    manifest_path = '../dataset/manifest.csv'
    make_manifest(files, manifest_path)
    split_manifest(manifest_path, train=0.6, test=0.2, valid=0.2, seed=42)
    build_windows_from_manifest(manifest_path, args.window_size, args.stride, args.max_window_num, args.output_folder_path)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--window_size', type=int, default=128)
    parser.add_argument('--stride', type=int, default=64)
    parser.add_argument('--max_window_num', type=int, default=24)
    parser.add_argument('--input_folder_path', type=str, default='../dataset/final_raw')
    parser.add_argument('--output_folder_path', type=str, default='../dataset/final_npy')
    args = parser.parse_args()

    processor(args)